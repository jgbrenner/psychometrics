{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOu/Y6MK7ARNc4tzAzZvdXa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgbrenner/psychometrics/blob/main/Copy_of_Final_model_PsychC9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generating Psychometric Scale Items in Polish Measuring Perfectionism Using Generative AI and Conducting Exploratory Graph Analysis**\n",
        "\n"
      ],
      "metadata": {
        "id": "UvoGrNfymB6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary Python packages\n",
        "!pip install openai groq rpy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1XIi-X0Jn2Xa",
        "outputId": "165bad8a-6771-43ca-cdae-b710a4e73c58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Collecting groq\n",
            "  Downloading groq-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: rpy2 in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rpy2) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from rpy2) (3.1.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from rpy2) (2024.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from rpy2) (5.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10.0->rpy2) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->rpy2) (3.0.2)\n",
            "Downloading groq-0.12.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary Python libraries\n",
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "from google.colab import drive, userdata"
      ],
      "metadata": {
        "id": "FWD-CauRn73x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the path where the R library will be saved in Google Drive\n",
        "library_path = '/content/drive/MyDrive/R_libraries'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(library_path):\n",
        "    os.makedirs(library_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzlYX_XAoCba",
        "outputId": "0c208ba6-abd6-41cf-bbdc-77fb62d4a383"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify rpy2 version\n",
        "import rpy2\n",
        "print(f\"rpy2 version: {rpy2.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfA-czOQoMrx",
        "outputId": "d1c5ceb2-a786-4239-f0ee-63e029929ad9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rpy2 version: 3.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the OpenAI API key from Colab secrets\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "else:\n",
        "    raise ValueError(\"OPENAI_API_KEY is not set or invalid.\")\n",
        "\n",
        "# Import OpenAI Client\n",
        "from openai import Client\n",
        "client = Client()"
      ],
      "metadata": {
        "id": "Uka6bARfoQeG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompting GPT-4o-mini to generate items\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"Jesteś ekspertem w psychometrii, który tworzy pytania testowe.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Wygeneruj po 3 stwierdzenia dla każdego z następujących konstruktów: \"\n",
        "            \"Perfekcjonizm skierowany na siebie: Tendencja do wymagania doskonałości od siebie samego, \"\n",
        "            \"Perfekcjonizm skierowany na innych: Stawianie wysokich oczekiwań wobec innych i krytyczna ocena ich osiągnięć, \"\n",
        "            \"Perfekcjonizm społecznie narzucony: Przekonanie, że inni oczekują od nas doskonałości. \"\n",
        "            \"Niech stwierdzenia będą zwięzłe i jasne,  odpowiednie do oceny w skali Likerta. \"\n",
        "            \"Provide the output ONLY in JSON format as a list of dictionaries, \"\n",
        "            \"without any additional text or explanation. \"\n",
        "            \"Each dictionary should have keys 'construct' and 'item'.\"\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "try:\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "        max_tokens=8048,\n",
        "        top_p=1,\n",
        "        stream=False\n",
        "    )\n",
        "    response_content = completion.choices[0].message.content\n",
        "    print(\"\\nGenerated Items:\\n\", response_content)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    response_content = \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InvfJWl4oV4N",
        "outputId": "41b018a8-4cb4-4ea0-baea-5c3713204f08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Items:\n",
            " ```json\n",
            "[\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na siebie\", \"item\": \"Czuję, że muszę osiągnąć doskonałość we wszystkim, co robię.\"},\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na siebie\", \"item\": \"Czuję się źle, gdy nie spełniam własnych wysokich oczekiwań.\"},\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na siebie\", \"item\": \"Zdarza mi się marnować czas na poprawianie drobnych błędów.\"},\n",
            "    \n",
            "    {\"construct\": \"Perfekcjonizm skierowany na innych\", \"item\": \"Oczekuję, że inni będą zawsze osiągać perfekcję.\"},\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na innych\", \"item\": \"Krytykuję innych, gdy nie spełniają moich wysokich standardów.\"},\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na innych\", \"item\": \"Często porównuję osiągnięcia innych do moich oczekiwań.\"},\n",
            "    \n",
            "    {\"construct\": \"Perfekcjonizm społecznie narzucony\", \"item\": \"Czuję, że społeczeństwo oczekuje ode mnie doskonałości.\"},\n",
            "    {\"construct\": \"Perfekcjonizm społecznie narzucony\", \"item\": \"Obawiam się, że inni będą mnie oceniać za moje niedoskonałości.\"},\n",
            "    {\"construct\": \"Perfekcjonizm społecznie narzucony\", \"item\": \"Mam wrażenie, że muszę spełniać oczekiwania innych, aby być akceptowany.\"}\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt to parse the JSON response\n",
        "try:\n",
        "    generated_items = json.loads(response_content)\n",
        "    items_df = pd.DataFrame(generated_items)\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"JSON parsing failed: {e}\")\n",
        "    # Attempt to extract valid JSON content from the response\n",
        "    json_match = re.search(r'\\[.*\\]', response_content, re.DOTALL)\n",
        "    if json_match:\n",
        "        json_str = json_match.group(0)\n",
        "        print(\"Extracted JSON String:\")\n",
        "        print(json_str)\n",
        "        try:\n",
        "            generated_items = json.loads(json_str)\n",
        "            items_df = pd.DataFrame(generated_items)\n",
        "        except json.JSONDecodeError as e2:\n",
        "            print(f\"Second JSON decoding attempt failed: {e2}\")\n",
        "            items_df = None\n",
        "    else:\n",
        "        print(\"No valid JSON found in the response.\")\n",
        "        items_df = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptyKbAMPolY5",
        "outputId": "4efe15bc-01ae-40a7-dabf-bf78628b5324"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON parsing failed: Expecting value: line 1 column 1 (char 0)\n",
            "Extracted JSON String:\n",
            "[\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na siebie\", \"item\": \"Czuję, że muszę osiągnąć doskonałość we wszystkim, co robię.\"},\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na siebie\", \"item\": \"Czuję się źle, gdy nie spełniam własnych wysokich oczekiwań.\"},\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na siebie\", \"item\": \"Zdarza mi się marnować czas na poprawianie drobnych błędów.\"},\n",
            "    \n",
            "    {\"construct\": \"Perfekcjonizm skierowany na innych\", \"item\": \"Oczekuję, że inni będą zawsze osiągać perfekcję.\"},\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na innych\", \"item\": \"Krytykuję innych, gdy nie spełniają moich wysokich standardów.\"},\n",
            "    {\"construct\": \"Perfekcjonizm skierowany na innych\", \"item\": \"Często porównuję osiągnięcia innych do moich oczekiwań.\"},\n",
            "    \n",
            "    {\"construct\": \"Perfekcjonizm społecznie narzucony\", \"item\": \"Czuję, że społeczeństwo oczekuje ode mnie doskonałości.\"},\n",
            "    {\"construct\": \"Perfekcjonizm społecznie narzucony\", \"item\": \"Obawiam się, że inni będą mnie oceniać za moje niedoskonałości.\"},\n",
            "    {\"construct\": \"Perfekcjonizm społecznie narzucony\", \"item\": \"Mam wrażenie, że muszę spełniać oczekiwania innych, aby być akceptowany.\"}\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the items to CSV if parsing succeeds\n",
        "if items_df is not None and not items_df.empty:\n",
        "    items_df.to_csv(\"generated_items_pool.csv\", index=False)\n",
        "    print(\"Generated items saved to 'generated_items_pool.csv'.\")\n",
        "else:\n",
        "    print(\"No items to save.\")\n",
        "    items_df = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBcZqSfcorZY",
        "outputId": "99f4f366-89d0-4c0b-b48d-72eab4503dec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated items saved to 'generated_items_pool.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the list of items\n",
        "if items_df is not None:\n",
        "    # Clean and validate item texts\n",
        "    items_df['item'] = items_df['item'].astype(str).str.strip()\n",
        "    # Filter out empty items\n",
        "    items_df = items_df[items_df['item'] != '']\n",
        "    # Reset index after filtering\n",
        "    items_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Now prepare item_texts for embeddings\n",
        "    item_texts = items_df[\"item\"].tolist()\n",
        "\n",
        "    # Set up the API endpoint and headers for OpenAI embeddings\n",
        "    embedding_endpoint = \"https://api.openai.com/v1/embeddings\"\n",
        "    embedding_model = \"text-embedding-3-small\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {openai_api_key}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    # Prepare the data payload\n",
        "    data = {\n",
        "        \"model\": embedding_model,\n",
        "        \"input\": item_texts\n",
        "    }\n",
        "\n",
        "    # Make the API request to generate embeddings\n",
        "    try:\n",
        "        response = requests.post(embedding_endpoint, headers=headers, json=data)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
        "            embeddings_array = None\n",
        "        else:\n",
        "            response_data = response.json()\n",
        "            # Extract embeddings\n",
        "            embeddings = [item['embedding'] for item in response_data['data']]\n",
        "            embeddings_array = np.array(embeddings)\n",
        "            print(f\"Embeddings generated successfully. Shape: {embeddings_array.shape}\")\n",
        "            # Save the embeddings\n",
        "            np.save(\"embeddings.npy\", embeddings_array)\n",
        "            print(\"Embeddings saved as 'embeddings.npy'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during embedding generation: {e}\")\n",
        "        embeddings_array = None\n",
        "else:\n",
        "    print(\"Error: items_df is not defined. Cannot proceed with embedding generation.\")\n",
        "    embeddings_array = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhnLh9VfotT3",
        "outputId": "6734a591-e1e3-4483-e4ba-16582844b711"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings generated successfully. Shape: (9, 1536)\n",
            "Embeddings saved as 'embeddings.npy'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure that items_df and embeddings_array have the same number of items\n",
        "if embeddings_array is not None and items_df is not None:\n",
        "    if embeddings_array.shape[0] != len(items_df):\n",
        "        print(f\"Embeddings count ({embeddings_array.shape[0]}) does not match items count ({len(items_df)}). Adjusting items_df.\")\n",
        "        # Truncate items_df to match embeddings_array size\n",
        "        items_df = items_df.iloc[:embeddings_array.shape[0]]\n",
        "        items_df.reset_index(drop=True, inplace=True)\n"
      ],
      "metadata": {
        "id": "ouqcOT5_o1vH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom abbreviations for constructs\n",
        "construct_abbreviations = {\n",
        "    \"Perfekcjonizm skierowany na siebie\": \"PSS\",\n",
        "    \"Perfekcjonizm społecznie narzucony\": \"PSP\",\n",
        "    \"Perfekcjonizm skierowany na innych\": \"PSI\"\n",
        "}"
      ],
      "metadata": {
        "id": "Mejem9GApPjo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply custom labels with error handling for unexpected constructs\n",
        "if items_df is not None:\n",
        "    items_df['item_label'] = items_df.apply(\n",
        "        lambda row: f\"{construct_abbreviations.get(row['construct'], 'UNK')}{row.name+1}\", axis=1\n",
        "    )\n",
        "\n",
        "    # Verify the generated labels\n",
        "    item_labels = items_df['item_label'].tolist()\n",
        "    constructs = items_df['construct'].tolist()\n",
        "\n",
        "    # Export labeled items for R\n",
        "    items_df.to_csv(\"psychometric_items.csv\", index=False)\n",
        "    print(\"Items exported to 'psychometric_items.csv'.\")\n",
        "else:\n",
        "    print(\"No items to label or export.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZSu4vORpWbL",
        "outputId": "0b6d4fbd-b786-4726-a5e0-9938ca58c66d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Items exported to 'psychometric_items.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for R analysis\n",
        "if embeddings_array is not None and items_df is not None:\n",
        "    # Pass variables from Python to R\n",
        "    # Install rpy2 for R and Python integration\n",
        "    %load_ext rpy2.ipython\n",
        "    %R -i embeddings_array -i item_labels -i constructs -i library_path\n",
        "else:\n",
        "    print(\"Cannot proceed to R analysis due to missing data.\")"
      ],
      "metadata": {
        "id": "eM8ZAYBepbk2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Set the custom library path\n",
        ".libPaths(library_path)\n",
        "\n",
        "# List of required packages\n",
        "required_packages <- c(\"EGAnet\", \"aricode\", \"psych\", \"dplyr\", \"stringr\", \"readr\", \"qgraph\")\n",
        "\n",
        "# Install and load necessary R packages\n",
        "for (pkg in required_packages) {\n",
        "    if (!requireNamespace(pkg, quietly = TRUE)) {\n",
        "        install.packages(pkg, lib = library_path, dependencies = TRUE)\n",
        "    }\n",
        "    library(pkg, character.only = TRUE)\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sFWvhKrOphvR",
        "outputId": "71f10883-164b-4105-f958-4a80b9b3fa4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \u001b[1;m\u001b[4;m\n",
            "EGAnet (version 2.1.0)\u001b[0m\u001b[0m \n",
            "\n",
            "For help getting started, see <https://r-ega.net> \n",
            "\n",
            "For bugs and errors, submit an issue to <https://github.com/hfgolino/EGAnet/issues>\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Verify dimensions of embeddings_array and item_labels\n",
        "print(dim(embeddings_array))  # Should return (number of items, embedding dimensions)\n",
        "print(length(item_labels))    # Should match the number of items in embeddings_array\n",
        "\n",
        "# Ensure the dimensions match\n",
        "if (nrow(embeddings_array) != length(item_labels)) {\n",
        "    stop(\"The number of rows in embeddings_array does not match the length of item_labels.\")\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8uzj34mp4Tc",
        "outputId": "c61d8662-621d-4eba-95a3-926d79862b05"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]    9 1536\n",
            "[1] 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "#Convert embeddings_array to matrix and assign row names\n",
        "embeddings_matrix <- as.matrix(embeddings_array)\n",
        "rownames(embeddings_matrix) <- item_labels\n",
        "\n",
        "# Compute the correlation matrix\n",
        "cor_matrix <- cor(t(embeddings_matrix))\n",
        "\n",
        "# Handle potential NA values in the correlation matrix\n",
        "cor_matrix[is.na(cor_matrix)] <- 0\n",
        "\n",
        "# Print the correlation matrix dimensions for verification\n",
        "print(dim(cor_matrix))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7uqczcYqOpf",
        "outputId": "74aad7f7-6871-4153-bff2-fcdf7cb1c0f5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 9 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Apply Unique Variable Analysis (UVA) to identify redundant items\n",
        "uva_result <- UVA(\n",
        "    data = cor_matrix,\n",
        "    n = nrow(cor_matrix),\n",
        "    method = \"wTO\",\n",
        "    threshold = 0.20  # Adjusted threshold as per AI-GENIE method\n",
        ")\n",
        "\n",
        "# Items to remove (redundant items)\n",
        "redundant_items <- uva_result$redundant\n",
        "\n",
        "# Print redundant items\n",
        "print(\"Redundant Items:\")\n",
        "print(redundant_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPxfZpNBq1dh",
        "outputId": "776d9416-e5ac-4b31-a8a4-2d590ee6b23d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Redundant Items:\"\n",
            "NULL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Remove redundant items from embeddings and correlation matrix\n",
        "embeddings_matrix_reduced <- embeddings_matrix[!rownames(embeddings_matrix) %in% redundant_items, ]\n",
        "cor_matrix_reduced <- cor_matrix[!rownames(cor_matrix) %in% redundant_items, !colnames(cor_matrix) %in% redundant_items]\n",
        "\n",
        "# Update item_labels and constructs\n",
        "item_labels_reduced <- item_labels[!item_labels %in% redundant_items]\n",
        "constructs_reduced <- constructs[!item_labels %in% redundant_items]\n",
        "\n",
        "# Ensure constructs_reduced and item_labels_reduced are vectors\n",
        "constructs_reduced <- as.vector(constructs_reduced)\n",
        "item_labels_reduced <- as.vector(item_labels_reduced)\n",
        "\n",
        "# Ensure alignment between constructs_reduced and item_labels_reduced\n",
        "names(constructs_reduced) <- item_labels_reduced\n"
      ],
      "metadata": {
        "id": "wbgu8pkirEkC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Print the structure of known_communities\n",
        "print(\"Structure of known_communities:\")\n",
        "str(known_communities)\n",
        "\n",
        "# Convert known_communities to a vector\n",
        "known_communities_vector <- unlist(known_communities, use.names = FALSE)\n",
        "\n",
        "# Similarly, ensure constructs_reduced is a vector\n",
        "constructs_reduced_vector <- unlist(constructs_reduced, use.names = FALSE)\n",
        "\n",
        "# Print the structures to confirm\n",
        "print(\"Structure of known_communities_vector:\")\n",
        "str(known_communities_vector)\n",
        "print(\"Structure of constructs_reduced_vector:\")\n",
        "str(constructs_reduced_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdH4E4VDz0ja",
        "outputId": "ccc896c3-8527-4297-f0a5-a7dd5bb9842a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Structure of known_communities:\"\n",
            "List of 9\n",
            " $ PSS1: chr \"Perfekcjonizm skierowany na siebie\"\n",
            " $ PSS2: chr \"Perfekcjonizm skierowany na siebie\"\n",
            " $ PSS3: chr \"Perfekcjonizm skierowany na siebie\"\n",
            " $ PSI4: chr \"Perfekcjonizm skierowany na innych\"\n",
            " $ PSI5: chr \"Perfekcjonizm skierowany na innych\"\n",
            " $ PSI6: chr \"Perfekcjonizm skierowany na innych\"\n",
            " $ PSP7: chr \"Perfekcjonizm społecznie narzucony\"\n",
            " $ PSP8: chr \"Perfekcjonizm społecznie narzucony\"\n",
            " $ PSP9: chr \"Perfekcjonizm społecznie narzucony\"\n",
            "[1] \"Structure of known_communities_vector:\"\n",
            " chr [1:9] \"Perfekcjonizm skierowany na siebie\" ...\n",
            "[1] \"Structure of constructs_reduced_vector:\"\n",
            " chr [1:9] \"Perfekcjonizm skierowany na siebie\" ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "%%R\n",
        "\n",
        "library(EGAnet)\n",
        "library(aricode)\n",
        "\n",
        "# Check structures before starting\n",
        "print(\"Structure of known_communities:\")\n",
        "str(known_communities)\n",
        "print(\"Structure of constructs_reduced:\")\n",
        "str(constructs_reduced)\n",
        "\n",
        "# Convert known_communities to a data frame\n",
        "known_df <- data.frame(\n",
        "    item_label = names(known_communities),\n",
        "    known_community = unlist(known_communities, use.names = FALSE),\n",
        "    stringsAsFactors = FALSE\n",
        ")\n",
        "\n",
        "# Initialize NMI values\n",
        "nmi_values <- numeric(10)\n",
        "\n",
        "# Debugging: Check the structure of cor_matrix_reduced\n",
        "print(\"Dimensions of cor_matrix_reduced:\")\n",
        "print(dim(cor_matrix_reduced))\n",
        "print(\"First 5x5 of cor_matrix_reduced:\")\n",
        "print(cor_matrix_reduced[1:5, 1:5])\n",
        "\n",
        "# Loop through step sizes to compute NMI\n",
        "for (step_size in 1:10) {\n",
        "    ega_result <- EGA(\n",
        "        data = cor_matrix_reduced,\n",
        "        corr = NULL,  # NULL because data is already a correlation matrix\n",
        "        n = nrow(cor_matrix_reduced),\n",
        "        model = \"glasso\",\n",
        "        algorithm = \"walktrap\",\n",
        "        steps = step_size,\n",
        "        plot.EGA = FALSE\n",
        "    )\n",
        "\n",
        "    # Check if EGA result contains valid communities\n",
        "    if (is.null(ega_result$wc) || length(ega_result$wc) == 0) {\n",
        "        warning(\"EGA did not find any communities at step size \", step_size)\n",
        "        nmi_values[step_size] <- NA\n",
        "        next\n",
        "    }\n",
        "\n",
        "    # Detected communities\n",
        "    detected_communities <- ega_result$wc\n",
        "\n",
        "    # Convert detected_communities to a data frame\n",
        "    detected_df <- data.frame(\n",
        "        item_label = names(detected_communities),\n",
        "        detected_community = unlist(detected_communities, use.names = FALSE),\n",
        "        stringsAsFactors = FALSE\n",
        "    )\n",
        "\n",
        "    # Merge known and detected communities on item_label\n",
        "    merged_df <- merge(known_df, detected_df, by = \"item_label\", all = FALSE)\n",
        "\n",
        "    # Ensure we have matching data\n",
        "    if (nrow(merged_df) == 0) {\n",
        "        warning(\"No matching items between known and detected communities at step size \", step_size)\n",
        "        nmi_values[step_size] <- NA\n",
        "        next\n",
        "    }\n",
        "\n",
        "    # Convert communities to factors\n",
        "    known_communities_factor <- as.factor(merged_df$known_community)\n",
        "    detected_communities_factor <- as.factor(merged_df$detected_community)\n",
        "\n",
        "    # Check lengths\n",
        "    length_known <- length(known_communities_factor)\n",
        "    length_detected <- length(detected_communities_factor)\n",
        "    cat(\"Length of known communities:\", length_known, \"\\n\")\n",
        "    cat(\"Length of detected communities:\", length_detected, \"\\n\")\n",
        "\n",
        "    # Remove NA values\n",
        "    valid_indices <- !is.na(known_communities_factor) & !is.na(detected_communities_factor)\n",
        "    if (sum(valid_indices) == 0) {\n",
        "        warning(\"No valid indices for NMI calculation at step size \", step_size)\n",
        "        nmi_values[step_size] <- NA\n",
        "        next\n",
        "    }\n",
        "\n",
        "    # Compute NMI\n",
        "    nmi <- NMI(\n",
        "        known_communities_factor[valid_indices],\n",
        "        detected_communities_factor[valid_indices]\n",
        "    )\n",
        "    nmi_values[step_size] <- nmi\n",
        "}\n",
        "\n",
        "# Identify optimal step size\n",
        "valid_nmi_indices <- which(!is.na(nmi_values))\n",
        "if (length(valid_nmi_indices) == 0) {\n",
        "    stop(\"No valid NMI values found across all step sizes.\")\n",
        "}\n",
        "optimal_step <- valid_nmi_indices[which.max(nmi_values[valid_nmi_indices])]\n",
        "\n",
        "# Output the results\n",
        "cat(\"Optimal step size:\", optimal_step, \"with NMI:\", nmi_values[optimal_step], \"\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oED8rYA3rOX5",
        "outputId": "7038c37c-7264-4569-fddc-3b2763c2c1f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Structure of known_communities:\"\n",
            "List of 9\n",
            " $ PSS1: chr \"Perfekcjonizm skierowany na siebie\"\n",
            " $ PSS2: chr \"Perfekcjonizm skierowany na siebie\"\n",
            " $ PSS3: chr \"Perfekcjonizm skierowany na siebie\"\n",
            " $ PSI4: chr \"Perfekcjonizm skierowany na innych\"\n",
            " $ PSI5: chr \"Perfekcjonizm skierowany na innych\"\n",
            " $ PSI6: chr \"Perfekcjonizm skierowany na innych\"\n",
            " $ PSP7: chr \"Perfekcjonizm społecznie narzucony\"\n",
            " $ PSP8: chr \"Perfekcjonizm społecznie narzucony\"\n",
            " $ PSP9: chr \"Perfekcjonizm społecznie narzucony\"\n",
            "[1] \"Structure of constructs_reduced:\"\n",
            "List of 9\n",
            " $ PSS1: chr \"Perfekcjonizm skierowany na siebie\"\n",
            " $ PSS2: chr \"Perfekcjonizm skierowany na siebie\"\n",
            " $ PSS3: chr \"Perfekcjonizm skierowany na siebie\"\n",
            " $ PSI4: chr \"Perfekcjonizm skierowany na innych\"\n",
            " $ PSI5: chr \"Perfekcjonizm skierowany na innych\"\n",
            " $ PSI6: chr \"Perfekcjonizm skierowany na innych\"\n",
            " $ PSP7: chr \"Perfekcjonizm społecznie narzucony\"\n",
            " $ PSP8: chr \"Perfekcjonizm społecznie narzucony\"\n",
            " $ PSP9: chr \"Perfekcjonizm społecznie narzucony\"\n",
            "[1] \"Dimensions of cor_matrix_reduced:\"\n",
            "[1] 9 9\n",
            "[1] \"First 5x5 of cor_matrix_reduced:\"\n",
            "          PSS1      PSS2      PSS3      PSI4      PSI5\n",
            "PSS1 1.0000000 0.5930455 0.5323751 0.6250089 0.5038925\n",
            "PSS2 0.5930455 1.0000000 0.5551850 0.4529410 0.6403320\n",
            "PSS3 0.5323751 0.5551850 1.0000000 0.4305697 0.5375738\n",
            "PSI4 0.6250089 0.4529410 0.4305697 1.0000000 0.4853252\n",
            "PSI5 0.5038925 0.6403320 0.5375738 0.4853252 1.0000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Error in \"set_default\" : \n",
            "  Input into 'argument' is 'NULL' type. Input is expected to be 'character' or 'function' type\n",
            "\n",
            " For more details on how to fix this error, see:\n",
            "https://r-ega.net/articles/errors.html#typeof-error\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error in \"set_default\" : \n",
            "  Input into 'argument' is 'NULL' type. Input is expected to be 'character' or 'function' type\n",
            "\n",
            " For more details on how to fix this error, see:\n",
            "https://r-ega.net/articles/errors.html#typeof-error\n"
          ]
        }
      ]
    }
  ]
}